{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and Tree Expansion Utilities\n",
    "\n",
    "This notebook contains two sets of utilities:\n",
    "\n",
    "- Tree expansion/trigrams (from `expand_trees.py`): helpers for generating local structural trigrams from a Penn-style parse tree.\n",
    "- Benepar parsing (from `parse_wmt.py`): helpers for building a SpaCy+Benepar pipeline and parsing sentences/files.\n",
    "\n",
    "Quick usage:\n",
    "- For trigrams: create an `nltk.Tree` from a bracketed string and iterate `generate_trigrams(tree)`.\n",
    "- For parsing: `nlp = load_benepar()` then parse sentences and read `_.parse_string` from the first sentence of the Doc.\n",
    "\n",
    "Dependencies for parsing demo: `spacy`, `benepar`, and models `en_core_web_sm` and `benepar_en3`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://nexus.corp.indeed.com/repository/pypi/simple\n",
      "Requirement already satisfied: nltk in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (3.9.1)\n",
      "Requirement already satisfied: spacy in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (3.8.7)\n",
      "Requirement already satisfied: benepar in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (0.2.0)\n",
      "Requirement already satisfied: click in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: setuptools in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (2.0.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (0.16.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from benepar) (2.7.1)\n",
      "Requirement already satisfied: transformers[tokenizers,torch]>=4.2.2 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from benepar) (4.54.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.91 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from benepar) (0.2.1)\n",
      "Requirement already satisfied: tokenizers>=0.9.4 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from benepar) (0.21.2)\n",
      "Requirement already satisfied: protobuf in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from benepar) (6.32.0)\n",
      "Requirement already satisfied: torch-struct>=0.5 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from benepar) (0.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from tokenizers>=0.9.4->benepar) (0.34.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.9.4->benepar) (2024.6.1)\n",
      "Requirement already satisfied: filelock in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.9.4->benepar) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.9.4->benepar) (6.0.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.9.4->benepar) (1.1.5)\n",
      "Requirement already satisfied: networkx in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from torch>=1.6.0->benepar) (3.2.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from torch>=1.6.0->benepar) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch>=1.6.0->benepar) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (0.5.3)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (1.8.1)\n",
      "Requirement already satisfied: psutil in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from accelerate>=0.26.0->transformers[tokenizers,torch]>=4.2.2->benepar) (6.0.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vvalluri/Library/Python/3.9/lib/python/site-packages (from jinja2->spacy) (2.1.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk spacy benepar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate trigrams of the form:\n",
    "ParentLabel -> Child₁ Child₂ … Childₙ , CurrentLabel , CurrentChildrenExpansion\n",
    "from a bracketed constituency parse read from STDIN.\n",
    "\"\"\"\n",
    "\n",
    "from nltk import Tree\n",
    "\n",
    "\n",
    "def child_repr(node: Tree) -> str:\n",
    "    \"\"\"\n",
    "    Return a leaf-stripped representation of a node suitable for\n",
    "    the 'children' part of the trigram, e.g.  (DT)  or  (NP (JJ) (NN)).\n",
    "    \"\"\"\n",
    "    # Leaf: omit the surface word entirely\n",
    "    if isinstance(node, str):\n",
    "        return \"\"\n",
    "    # Pre-terminal: POS tag with a single word child\n",
    "    if len(node) == 1 and isinstance(node[0], str):\n",
    "        return f\"({node.label()})\"\n",
    "    # Internal node: show its label plus its own children's representations\n",
    "    inner = \" \".join(child_repr(c) for c in node)\n",
    "    return f\"({node.label()} {inner})\"\n",
    "\n",
    "\n",
    "def expansion(node: Tree) -> str:\n",
    "    \"\"\"Return space-separated representations of *all* immediate children.\"\"\"\n",
    "    return \" \".join(child_repr(c) for c in node)\n",
    "\n",
    "\n",
    "def generate_trigrams(tree: Tree, sent_id=None):\n",
    "    \"\"\"Yield trigram strings in the required format.\"\"\"\n",
    "    for parent in tree.subtrees():\n",
    "        # List of this parent's immediate children labels\n",
    "        child_labels = \" \".join(c.label() for c in parent if isinstance(c, Tree))\n",
    "        for child in parent:\n",
    "            if isinstance(child, Tree):  # ignore pre-terminals when they are 'Current'\n",
    "                exp = expansion(child)\n",
    "                if exp:\n",
    "                    trigram = f\"{parent.label()} -> {child_labels}, {child.label()}, {exp}\"\n",
    "                    if sent_id is not None:\n",
    "                        yield f\"SENT_{sent_id}\\t{trigram}\"\n",
    "                    else:\n",
    "                        yield trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vvalluri/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read one-sentence-per-line text, parse each sentence with Benepar,\n",
    "and write the corresponding Penn-style constituency trees.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- choose a parser implementation ----------------------------------------\n",
    "# Here we use SpaCy + Benepar.  Feel free to swap in CoreNLP, Berkeley, etc.\n",
    "import spacy, benepar\n",
    "\n",
    "def load_benepar():\n",
    "    \"\"\"Return a SpaCy pipeline that yields `token._.parse_string`.\"\"\"\n",
    "    # Try full English model; fall back to a blank pipeline with sentence splitter\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"lemmatizer\"])\n",
    "    except Exception:\n",
    "        nlp = spacy.blank(\"en\")\n",
    "        if \"sentencizer\" not in nlp.pipe_names:\n",
    "            nlp.add_pipe(\"sentencizer\")\n",
    "    # Ensure benepar model is available and added\n",
    "    try:\n",
    "        nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
    "    except Exception:\n",
    "        try:\n",
    "            if hasattr(benepar, \"download\"):\n",
    "                benepar.download(\"benepar_en3\")\n",
    "            nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Benepar model 'benepar_en3' is required and could not be installed.\"\n",
    "            ) from e\n",
    "    return nlp\n",
    "\n",
    "def parse_file(in_path: Path, out_path: Path, nlp):\n",
    "    with in_path.open(encoding=\"utf8\") as fin, out_path.open(\"w\", encoding=\"utf8\") as fout:\n",
    "        for line_no, sent in enumerate(fin, 1):\n",
    "            sent = sent.strip()\n",
    "            if not sent:\n",
    "                fout.write(\"\\n\")\n",
    "                continue\n",
    "            doc = nlp(sent)\n",
    "            # Benepar attaches the parse to the *first* sentence in the Doc\n",
    "            tree = next(doc.sents)._.parse_string\n",
    "            fout.write(tree + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT_1\tS -> NP VP, NP, (DT) (NN)\n",
      "SENT_1\tS -> NP VP, VP, (VBZ) (VP (VBG) (PP (IN) (NP (DT) (NN))))\n",
      "SENT_1\tVP -> VBZ VP, VP, (VBG) (PP (IN) (NP (DT) (NN)))\n",
      "SENT_1\tVP -> VBG PP, PP, (IN) (NP (DT) (NN))\n",
      "SENT_1\tPP -> IN NP, NP, (DT) (NN)\n"
     ]
    }
   ],
   "source": [
    "# Example: generate trigrams from a simple parse\n",
    "from nltk import Tree\n",
    "\n",
    "example = \"(S (NP (DT The) (NN boy)) (VP (VBZ is) (VP (VBG playing) (PP (IN with) (NP (DT the) (NN ball))))))\"\n",
    "tree = Tree.fromstring(example)\n",
    "for tri in generate_trigrams(tree, sent_id=1):\n",
    "    print(tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (DT The) (NN boy)) (VP (VBZ is) (VP (VBG playing) (PP (IN with) (NP (DT the) (NN ball))))))\n"
     ]
    }
   ],
   "source": [
    "# Example: parse a sentence with SpaCy + Benepar\n",
    "# Requires: pip install spacy benepar && python -m spacy download en_core_web_sm\n",
    "# If benepar model is missing: in Python, run: benepar.download('benepar_en3')\n",
    "\n",
    "try:\n",
    "    nlp = load_benepar()\n",
    "    doc = nlp(\"The boy is playing with the ball\")\n",
    "    parse_str = next(doc.sents)._.parse_string\n",
    "    print(parse_str)\n",
    "except Exception as e:\n",
    "    print(\"Parsing demo failed. Ensure spacy, benepar, and models are installed.\")\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ready. Parsing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing:   0%|          | 0/160239 [00:00<?, ?sent/s]"
     ]
    }
   ],
   "source": [
    "# Parse the dataset file row-wise with progress and write bracketed parses\n",
    "from pathlib import Path\n",
    "import time, string\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    tqdm = None\n",
    "\n",
    "# Input file: one sentence per line\n",
    "in_path = Path(\"/Users/vvalluri/research/indic_comp/iwslt_2014_train/train.en.for.features\")\n",
    "# Output file: append .parse to the input filename\n",
    "out_path = Path(str(in_path) + \".parse\")\n",
    "\n",
    "# Count total lines for progress (fast for 160k)\n",
    "try:\n",
    "    total_lines = sum(1 for _ in in_path.open(encoding=\"utf8\"))\n",
    "except Exception:\n",
    "    total_lines = None\n",
    "\n",
    "start = time.time()\n",
    "nlp = load_benepar()\n",
    "print(\"Pipeline ready. Parsing...\")\n",
    "\n",
    "# Stream line-by-line, updating progress\n",
    "if tqdm and total_lines:\n",
    "    pbar = tqdm(total=total_lines, desc=\"Parsing\", unit=\"sent\")\n",
    "else:\n",
    "    pbar = None\n",
    "\n",
    "with in_path.open(encoding=\"utf8\") as fin, out_path.open(\"w\", encoding=\"utf8\") as fout:\n",
    "    for line in fin:\n",
    "        sent = line.strip()\n",
    "        sent = sent.rstrip(string.punctuation)\n",
    "\n",
    "        if not sent:\n",
    "            fout.write(\"\\n\")\n",
    "        else:\n",
    "            doc = nlp(sent)\n",
    "            tree = next(doc.sents)._.parse_string\n",
    "            fout.write(tree + \"\\n\")\n",
    "        if pbar:\n",
    "            pbar.update(1)\n",
    "        \n",
    "if pbar:\n",
    "    pbar.close()\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Done. Wrote parses to: {out_path}\")\n",
    "print(f\"Elapsed: {elapsed/60:.1f} minutes (approx)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing:   0%|          | 0/160239 [00:19<?, ?sent/s]\n",
      "Trigrams: 100%|██████████| 160239/160239 [00:26<00:00, 6077.11tree/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote trigrams to: /Users/vvalluri/research/indic_comp/parsed_trees.trigrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate trigrams from the parsed output file with progress\n",
    "from pathlib import Path\n",
    "from nltk import Tree\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    tqdm = None\n",
    "\n",
    "parsed_path = Path(\"/Users/vvalluri/research/indic_comp/parsed_trees\")\n",
    "out_trigrams = Path(str(parsed_path) + \".trigrams\")\n",
    "\n",
    "# Count lines for progress bar\n",
    "try:\n",
    "    total_lines = sum(1 for _ in parsed_path.open(encoding=\"utf8\"))\n",
    "except Exception:\n",
    "    total_lines = None\n",
    "\n",
    "if tqdm and total_lines:\n",
    "    pbar = tqdm(total=total_lines, desc=\"Trigrams\", unit=\"tree\")\n",
    "else:\n",
    "    pbar = None\n",
    "\n",
    "with parsed_path.open(encoding=\"utf8\") as fin, out_trigrams.open(\"w\", encoding=\"utf8\") as fout:\n",
    "    for sent_id, line in enumerate(fin, 1):\n",
    "        tree_str = line.strip()\n",
    "        if not tree_str:\n",
    "            fout.write(f\"SENT_{sent_id}\\t\\n\")\n",
    "        else:\n",
    "            tree = Tree.fromstring(tree_str)\n",
    "            for tri in generate_trigrams(tree, sent_id=sent_id):\n",
    "                fout.write(tri + \"\\n\")\n",
    "        if pbar:\n",
    "            pbar.update(1)\n",
    "\n",
    "if pbar:\n",
    "    pbar.close()\n",
    "\n",
    "print(f\"Done. Wrote trigrams to: {out_trigrams}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
